% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Lrnr_sl.R
\docType{class}
\name{Lrnr_sl}
\alias{Lrnr_sl}
\title{The Super Learner Algorithm}
\format{
An \code{\link[R6]{R6Class}} object inheriting from
\code{\link{Lrnr_base}}.
}
\value{
A learner object inheriting from \code{\link{Lrnr_base}} with
methods for training and prediction. For a full list of learner
functionality, see the complete documentation of \code{\link{Lrnr_base}}.
}
\description{
Learner that encapsulates the Super Learner algorithm. Fits metalearner on
cross-validated predictions from learners. Then forms a pipeline with the
learners.
}
\section{Parameters}{

\itemize{
\item \code{learners}: The "library" of user-specified algorithms for the
super learner to consider as candidates.
\item \code{metalearner = NULL}: The metalearner to be fit on cross-validated
predictions from the candidates. If \code{NULL}, the
\code{\link{default_metalearner}} is used to construct a metalearner
based on the \code{outcome_type} of the training \code{task}.
\item \code{cv_control = NULL}: Optional list of arguments that will be used to
define a specific cross-validation fold structure for fitting the
super learner. Intended for use in a nested cross-validation scheme,
such as cross-validated super learner (\code{\link{CV_lrnr_sl}}) or
when \code{Lrnr_sl} is considered in the list of candidate
\code{learners} in another \code{Lrnr_sl}. Includes the arguments
listed below, and any others to be passed to
\code{\link[origami]{fold_funs}}:
\itemize{
\item \code{strata = NULL}: Optional column name to define stratified
cross-validation folds. If \code{NULL} and if
\code{task$outcome_type$type} is binary or categorical, then the
default behavior is to consider stratified cross-validation, where
the strata are defined with respect to the outcome. To override
the default behavior, i.e., to not consider stratified
cross-validation when \code{strata = NULL} and
\code{task$outcome_type$type} is binary or categorical is not
\code{NULL}, set \code{strata = "none"}.
\item \code{id}: Optional column name to define clustered cross-validation,
so dependent units are placed together in the same training sets
and in the same validation set. If \code{NULL} and
\code{task$nodes$id} is not \code{NULL}, then the default behavior
is to consider \code{task$nodes$id} for defining clustered
cross-validation scheme. To override the default behavior, i.e.,
to not consider clustered cross-validation when
\code{task$nodes$id} is not \code{NULL}, set \code{id = "none"}.
\item \code{fold_fun}: A function indicating the \pkg{origami}
cross-validation scheme to use, such as
\code{\link[origami]{folds_vfold}} for V-fold cross-validation.
See \code{\link[origami]{fold_funs}} for a list of possibilities.
If \code{NULL} and if other \code{cv_control} arguments are
specified, e.g., \code{V}, \code{strata} or \code{id}, then the
default behavior is to set \code{fold_fun = folds_vfold}.
\item \code{...}: Other arguments to be passed to \code{fold_fun}, such as
\code{V} for \code{fold_fun = folds_vfold}. See
\code{\link[origami]{fold_funs}} for a list fold-function-specific
possible arguments.
}
\item \code{keep_extra = TRUE}: Stores all sub-parts of the super learner
computation. When \code{FALSE}, the resulting object has a memory
footprint that is significantly reduced through the discarding of
intermediary data structures.
\item \code{...}: Any additional parameters that can be considered by
\code{\link{Lrnr_base}}.
}
}

\examples{
data(cpp_imputed)
covs <- c("apgar1", "apgar5", "parity", "gagebrth", "mage", "meducyrs")
task <- sl3_Task$new(cpp_imputed, covariates = covs, outcome = "haz")
# this is just for illustrative purposes, not intended for real applications
# of the super learner!
glm_lrn <- Lrnr_glm$new()
ranger_lrn <- Lrnr_ranger$new()
lasso_lrn <- Lrnr_glmnet$new()
ensemble_sl <- Lrnr_sl$new(learners = list(glm_lrn, ranger_lrn, lasso_lrn))
ensemble_sl_fit <- ensemble_sl$train(task)
# example with cv_control, where Lrnr_sl included as a candidate
ensemble_sl2 <- Lrnr_sl$new(
  learners = list(glm_lrn, ranger_lrn, lasso_lrn),
  cv_control = list(fold_fun = origami::folds_vfold, V = 5L)
)
discrete_sl <- Lrnr_sl$new(
  learners = list(glm_lrn, ranger_lrn, lasso_lrn, ensemble_sl2),
  metalearner = Lrnr_cv_selector$new(loss_squared_error)
)
discrete_sl_fit <- discrete_sl$train(task)
# example with cv_control, where we use cross-validated super learner
cv_sl <- CV_lrnr_sl(
  lrnr_sl = ensemble_sl2, task = task, eval_fun = loss_squared_error
)
}
\seealso{
Other Learners: 
\code{\link{Custom_chain}},
\code{\link{Lrnr_HarmonicReg}},
\code{\link{Lrnr_arima}},
\code{\link{Lrnr_bartMachine}},
\code{\link{Lrnr_base}},
\code{\link{Lrnr_bayesglm}},
\code{\link{Lrnr_bilstm}},
\code{\link{Lrnr_caret}},
\code{\link{Lrnr_cv_selector}},
\code{\link{Lrnr_cv}},
\code{\link{Lrnr_dbarts}},
\code{\link{Lrnr_define_interactions}},
\code{\link{Lrnr_density_discretize}},
\code{\link{Lrnr_density_hse}},
\code{\link{Lrnr_density_semiparametric}},
\code{\link{Lrnr_earth}},
\code{\link{Lrnr_expSmooth}},
\code{\link{Lrnr_gam}},
\code{\link{Lrnr_ga}},
\code{\link{Lrnr_gbm}},
\code{\link{Lrnr_glm_fast}},
\code{\link{Lrnr_glmnet}},
\code{\link{Lrnr_glmtree}},
\code{\link{Lrnr_glm}},
\code{\link{Lrnr_grf}},
\code{\link{Lrnr_gru_keras}},
\code{\link{Lrnr_gts}},
\code{\link{Lrnr_h2o_grid}},
\code{\link{Lrnr_hal9001}},
\code{\link{Lrnr_haldensify}},
\code{\link{Lrnr_hts}},
\code{\link{Lrnr_independent_binomial}},
\code{\link{Lrnr_lightgbm}},
\code{\link{Lrnr_lstm_keras}},
\code{\link{Lrnr_mean}},
\code{\link{Lrnr_multiple_ts}},
\code{\link{Lrnr_multivariate}},
\code{\link{Lrnr_nnet}},
\code{\link{Lrnr_nnls}},
\code{\link{Lrnr_optim}},
\code{\link{Lrnr_pca}},
\code{\link{Lrnr_pkg_SuperLearner}},
\code{\link{Lrnr_polspline}},
\code{\link{Lrnr_pooled_hazards}},
\code{\link{Lrnr_randomForest}},
\code{\link{Lrnr_ranger}},
\code{\link{Lrnr_revere_task}},
\code{\link{Lrnr_rpart}},
\code{\link{Lrnr_rugarch}},
\code{\link{Lrnr_screener_augment}},
\code{\link{Lrnr_screener_coefs}},
\code{\link{Lrnr_screener_correlation}},
\code{\link{Lrnr_screener_importance}},
\code{\link{Lrnr_solnp_density}},
\code{\link{Lrnr_solnp}},
\code{\link{Lrnr_stratified}},
\code{\link{Lrnr_subset_covariates}},
\code{\link{Lrnr_svm}},
\code{\link{Lrnr_tsDyn}},
\code{\link{Lrnr_ts_weights}},
\code{\link{Lrnr_xgboost}},
\code{\link{Pipeline}},
\code{\link{Stack}},
\code{\link{define_h2o_X}()},
\code{\link{undocumented_learner}}
}
\concept{Learners}
\keyword{data}
